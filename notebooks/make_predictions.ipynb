{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes predictions of unlabeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and dependencies\n",
    "import tensorflow as tf \n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 100 images belonging to 1 classes.\n"
    }
   ],
   "source": [
    "test_dir = 'F:/Nilgai_photo_database/Nilgai Classifier/Nilgai/sample_images/'\n",
    "img_dir = 'F:/Nilgai_photo_database/Nilgai Classifier/Nilgai/sample_images/images/'\n",
    "pred_dir = 'F:/Nilgai_photo_database/Nilgai Classifier/Nilgai/predictions/'\n",
    "mulit_model_path = 'F:/Nilgai_photo_database/Nilgai Classifier/Nilgai/models/FINALE_MULTI_multi_20_epo_200K_'\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "IMG_HEIGHT = 299\n",
    "IMG_WIDTH = 299\n",
    "\n",
    "def img_crop(img):\n",
    "    # for cropping\n",
    "    offset_width = 0\n",
    "    offset_height = 9\n",
    "    target_height = 273\n",
    "    target_width = 299\n",
    "\n",
    "    # for random width shift\n",
    "    wrg = 0.5 \n",
    "    hrg = 0.0\n",
    "    row_axis =  2\n",
    "    channel_axis = 1\n",
    "\n",
    "    new_img = tf.image.crop_to_bounding_box(img, offset_height, offset_width, target_height, target_width)\n",
    "    new_img = tf.image.resize(new_img, (299,299))\n",
    "    return new_img\n",
    "\n",
    "img_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, preprocessing_function=img_crop)\n",
    "\n",
    "test_generator = img_generator.flow_from_directory(directory=str(test_dir),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=False,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode= None)\n",
    "# load model\n",
    "multi_model = tf.keras.models.load_model(mulit_model_path, compile=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred_steps=np.ceil(test_generator.samples/test_generator.batch_size)\n",
    "\n",
    "pred = multi_model.predict(test_generator, verbose=1, workers=4, steps=pred_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-2d49bdb7744a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m  \u001b[1;34m'Unknown'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m  'White-tailed deer': 24}\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-2d49bdb7744a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     24\u001b[0m  \u001b[1;34m'Unknown'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m  'White-tailed deer': 24}\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# define class names and create and index for future mapping\n",
    "class_names = [('Armadillo', 0),\n",
    " ('Birds', 1),\n",
    " ('Bobcat', 2),\n",
    " ('Cattle', 3),\n",
    " ('Coyote', 4),\n",
    " ('Dog', 5),\n",
    " ('Exotics, Other', 6),\n",
    " ('Horse', 7),\n",
    " ('Humans', 8),\n",
    " ('Mouse', 9),\n",
    " ('Nilgai', 10),\n",
    " ('None', 11),\n",
    " ('Ocelot', 12),\n",
    " ('Opossum', 13),\n",
    " ('Pig', 14),\n",
    " ('Rabbit', 15),\n",
    " ('Raccoon', 16),\n",
    " ('Rat', 17),\n",
    " ('Skunk', 18),\n",
    " ('Spider', 19),\n",
    " ('Squirrel', 20),\n",
    " ('Tortoise', 21),\n",
    " ('Turkey', 22),\n",
    " ('Unknown', 23),\n",
    " ('White-tailed Deer', 24)]\n",
    "class_names = np.array([key.title() for key, value in class_names])\n",
    "predicted_id = np.argmax(pred, axis=-1)\n",
    "predicted_label_batch = class_names[predicted_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in class_names:\n",
    "    img_path = os.path.join(pred_dir, str(i))\n",
    "    try:\n",
    "        os.makedirs(img_path, exist_ok=False)\n",
    "    except:\n",
    "        print(\"The \" + '\"' + str(i) + '\"' + \" folder already exists. Check your prediction path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map prediction name to labels, move images to repsective folders, and print results\n",
    "## Todo: make this a function\n",
    "for i, logits in enumerate(pred):\n",
    "    class_idx = tf.argmax(logits).numpy()\n",
    "    p = logits[class_idx]\n",
    "    name = class_names[class_idx]\n",
    "    img_name = os.path.split(test_generator.filenames[i])[1]\n",
    "    samp_name = os.path.splitext(img_name)[0]\n",
    "    img = os.path.join(img_dir,img_name)\n",
    "    dst = os.path.join(pred_dir, name)\n",
    "    shutil.copy(img, dst)\n",
    "    print(\"\\n{} prediction: {} ({:4.2f}%)\".format(samp_name, name, 100*p))\n",
    "    print(\"Moved to Nilgai/predictions/\" + name + \".\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bittf21conda2d5e8e5529ee4229b3fd9d7f11fc5f96",
   "display_name": "Python 3.7.7 64-bit ('tf2.1': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}